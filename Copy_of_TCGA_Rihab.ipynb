{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of TCGA_Rihab.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LJlWFOh5uDFY",
        "qm2_QBd_aHlY",
        "J8AgvM3w7pfi",
        "pkZDV37a76St"
      ],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/guang-zh/ai4genomics_TCGA_Benchmark/blob/master/Copy_of_TCGA_Rihab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uo9rS267sigj",
        "colab_type": "text"
      },
      "source": [
        "## Upload Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "60njm4wTUdGM",
        "colab_type": "code",
        "outputId": "99c7a477-36c8-4931-c858-3907e733ef0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from os.path import join\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "ROOT = \"/content/drive\"\n",
        "drive.mount(ROOT)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAlIwp9VUvH6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "PROJ = \"My Drive/AI4genomics/TCGA_Benchmark-master\" # This is a custom path.\n",
        "PROJECT_PATH = join(ROOT, PROJ)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAf0H0bmUwEj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from importlib.machinery import SourceFileLoader\n",
        "TCGA = SourceFileLoader('tcga', join(PROJECT_PATH, 'meta_dataloader/TCGA.py')).load_module()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK2jeX27UzJr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sys\n",
        "import numpy as np\n",
        "import collections\n",
        "import sklearn.metrics\n",
        "import sklearn.model_selection\n",
        "import random\n",
        "from collections import OrderedDict\n",
        "import pandas as pd\n",
        "from torch.optim import Optimizer\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from torch import Tensor\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "import pdb"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mDnJPt5hU5Vl",
        "colab_type": "code",
        "outputId": "7ee5f02a-5109-478c-85a0-39bc0e85a3b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Definition de l'ensemble des tasks\n",
        "tasks = TCGA.TCGAMeta(min_samples_per_class=10)    "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/AI4genomics/TCGA_Benchmark-master/meta_dataloader/TCGA.py:39: H5pyDeprecationWarning: The default file mode will change to 'r' (read-only) in h5py 3.0. To suppress this warning, pass the mode you need to h5py.File(), or set the global default h5.get_config().default_file_mode, or set the environment variable H5PY_DEFAULT_READONLY=1. Available modes are: 'r', 'r+', 'w', 'w-'/'x', 'a'. See the docs for details.\n",
            "  f = h5py.File(hdf_file)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFMdWLTUTt9k",
        "colab_type": "code",
        "outputId": "a89587e0-0e81-4327-8e3b-6c00315eed55",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# To identify the number of existing tasks in the metaloader\n",
        "len(tasks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "174"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3sCE-ir6oAIU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "task = TCGA.TCGATask(tasks.task_ids[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZp2vuO7o1e6",
        "colab_type": "text"
      },
      "source": [
        "## Load the dataset (Inputs and Labels) & the train-test steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQk7aZBymYmZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_all_tasks_sets(tasks):\n",
        "\n",
        "  if os.path.isfile(join(PROJECT_PATH, 'meta_dataloader/all_X.npy')):\n",
        "    all_X = np.load(join(PROJECT_PATH, 'meta_dataloader/all_X.npy'))\n",
        "    all_Y = np.load(join(PROJECT_PATH, 'meta_dataloader/all_Y.npy'))\n",
        "    \n",
        "  else:\n",
        "    all_X = []\n",
        "    all_Y = []\n",
        "    \n",
        "  cpt = 0\n",
        "\n",
        "  for taskid in tasks.task_ids:\n",
        "      cpt += 1\n",
        "      print(cpt)\n",
        "        \n",
        "      task = TCGA.TCGATask(taskid)\n",
        "      all_X.append(task._samples)\n",
        "      all_Y.append(task._labels)\n",
        "        \n",
        "  all_X = np.concatenate(all_X, axis=0)\n",
        "  all_Y = np.concatenate(all_Y, axis=0)\n",
        "        \n",
        "  np.save(join(PROJECT_PATH, 'meta_dataloader/all_X.npy'), all_X)\n",
        "  np.save(join(PROJECT_PATH, 'meta_dataloader/all_Y.npy'), all_Y)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(all_X, \n",
        "                                                                              all_Y, \n",
        "                                                                              train_size=0.8,\n",
        "                                                                              test_size=0.2)\n",
        "  all_train_set = TensorDataset( Tensor(X_train), Tensor(y_train))\n",
        "  all_test_set = TensorDataset( Tensor(X_test), Tensor(y_test))\n",
        "    \n",
        "  return all_train_set, all_test_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5ceowEcMjzV",
        "colab_type": "code",
        "outputId": "6dc6dd58-4627-443d-c866-ebea06d1352d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "all_train_set, all_test_set = load_all_tasks_sets(tasks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n",
            "4\n",
            "5\n",
            "6\n",
            "7\n",
            "8\n",
            "9\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "15\n",
            "16\n",
            "17\n",
            "18\n",
            "19\n",
            "20\n",
            "21\n",
            "22\n",
            "23\n",
            "24\n",
            "25\n",
            "26\n",
            "27\n",
            "28\n",
            "29\n",
            "30\n",
            "31\n",
            "32\n",
            "33\n",
            "34\n",
            "35\n",
            "36\n",
            "37\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "43\n",
            "44\n",
            "45\n",
            "46\n",
            "47\n",
            "48\n",
            "49\n",
            "50\n",
            "51\n",
            "52\n",
            "53\n",
            "54\n",
            "55\n",
            "56\n",
            "57\n",
            "58\n",
            "59\n",
            "60\n",
            "61\n",
            "62\n",
            "63\n",
            "64\n",
            "65\n",
            "66\n",
            "67\n",
            "68\n",
            "69\n",
            "70\n",
            "71\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "76\n",
            "77\n",
            "78\n",
            "79\n",
            "80\n",
            "81\n",
            "82\n",
            "83\n",
            "84\n",
            "85\n",
            "86\n",
            "87\n",
            "88\n",
            "89\n",
            "90\n",
            "91\n",
            "92\n",
            "93\n",
            "94\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "99\n",
            "100\n",
            "101\n",
            "102\n",
            "103\n",
            "104\n",
            "105\n",
            "106\n",
            "107\n",
            "108\n",
            "109\n",
            "110\n",
            "111\n",
            "112\n",
            "113\n",
            "114\n",
            "115\n",
            "116\n",
            "117\n",
            "118\n",
            "119\n",
            "120\n",
            "121\n",
            "122\n",
            "123\n",
            "124\n",
            "125\n",
            "126\n",
            "127\n",
            "128\n",
            "129\n",
            "130\n",
            "131\n",
            "132\n",
            "133\n",
            "134\n",
            "135\n",
            "136\n",
            "137\n",
            "138\n",
            "139\n",
            "140\n",
            "141\n",
            "142\n",
            "143\n",
            "144\n",
            "145\n",
            "146\n",
            "147\n",
            "148\n",
            "149\n",
            "150\n",
            "151\n",
            "152\n",
            "153\n",
            "154\n",
            "155\n",
            "156\n",
            "157\n",
            "158\n",
            "159\n",
            "160\n",
            "161\n",
            "162\n",
            "163\n",
            "164\n",
            "165\n",
            "166\n",
            "167\n",
            "168\n",
            "169\n",
            "170\n",
            "171\n",
            "172\n",
            "173\n",
            "174\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7aZauJnsRoY",
        "colab_type": "text"
      },
      "source": [
        "## **Part A - VAE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iAXnY8ZarqxS",
        "colab_type": "text"
      },
      "source": [
        "# Step 1.1 - Load and preprocess the dataset for the VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGHJuY8wuKfm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# You should have train_set instead of X_train as input\n",
        "# 32 is the max batch size to use \n",
        "train_loader = torch.utils.data.DataLoader(all_train_set, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(all_test_set, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSkv850dMBi3",
        "colab_type": "code",
        "outputId": "ce07e469-6a14-4351-d2f6-9c1ee1799722",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(len(train_loader))\n",
        "print(len(test_loader))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1295\n",
            "324\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "341HK-JqrpCD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_KNQzQBNZZa-",
        "colab_type": "text"
      },
      "source": [
        "# Step 1.2. Define the VAE Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE7yZG4eZNve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils import spectral_norm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Dummy(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Helper class that allows you to do nothing. Replaces `lambda x: x`.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "\n",
        "class LinearBatch(nn.Module):\n",
        "    \"\"\"A linear layer with batch normalization.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, bias=True):\n",
        "        super(LinearBatch, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim, bias=bias)\n",
        "        self.batch_norm = nn.BatchNorm1d(output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return self.batch_norm(out)\n",
        "\n",
        "\n",
        "class LinearSpec(nn.Module):\n",
        "    \"\"\"A linear layer with spectral normalization.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, bias=True):\n",
        "        super(LinearSpec, self).__init__()\n",
        "        self.linear = spectral_norm(nn.Linear(input_dim, output_dim, bias=bias))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "class LinearLayers(nn.Module):\n",
        "    \"\"\"\n",
        "    A basic feed forward network with configurable dropout and layer-wise\n",
        "    normalization.\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, dropout=0, norm='none', modulelist=False,\n",
        "                 bias=True, activate_final=True):\n",
        "        super(LinearLayers, self).__init__()\n",
        "\n",
        "        norm_dict = {\n",
        "            'batch': LinearBatch, 'spectral': LinearSpec, 'none': nn.Linear}\n",
        "\n",
        "        assert 0 <= dropout < 1\n",
        "        assert norm in norm_dict.keys()\n",
        "\n",
        "        # Set up the linear layers.\n",
        "        self.linear = norm_dict[norm]\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        arch = []\n",
        "        n_layers = len(layers)\n",
        "        for i in range(n_layers-1):\n",
        "            arch.append(self.linear(layers[i], layers[i+1], bias=bias))\n",
        "\n",
        "            # Add activation to all layers, except the final one optionally.\n",
        "            if activate_final or i+1 < n_layers-1:\n",
        "                arch.append(self.activation)\n",
        "\n",
        "                # Only dropout the activated layers.\n",
        "                if dropout > 0:\n",
        "                    arch.append(self.dropout)\n",
        "\n",
        "        # Allows for the linear layer to be a passthrough in the case that\n",
        "        # the number of layers requested is empty or a single value.\n",
        "        if len(arch) > 0:\n",
        "            if modulelist:\n",
        "                self.model = nn.ModuleList(arch)\n",
        "            else:\n",
        "                self.model = nn.Sequential(*arch)\n",
        "        else:\n",
        "            self.model = Dummy()\n",
        "\n",
        "    def embed(self, X):\n",
        "        return self.model(X)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.embed(X)\n",
        "\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A basic feed forward classifier architecture with configurable dropout and\n",
        "    layer-wise normalization.\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, dropout=0, norm='none'):\n",
        "        \"\"\"\n",
        "        An MLP vanilla antoencoder.\n",
        "        \"\"\"\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        # assert num_classes >= 1\n",
        "        self.encoder = LinearLayers(layers=layers, dropout=dropout, norm=norm)\n",
        "        self.decoder = LinearLayers(layers=layers[::-1], dropout=dropout,\n",
        "                                    norm=norm, activate_final=False)\n",
        "        self.criterion = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "    def embed(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def forward(self, x, fingerprint=0, compound=0, line=0):\n",
        "        z = self.encoder(x)\n",
        "        X_prime = self.decoder(z)\n",
        "        return {'z': z, 'x_prime': X_prime, 'x': x}\n",
        "\n",
        "    def loss(self, outputs):\n",
        "        recon_loss = self.criterion(outputs['x_prime'], outputs['x'])\n",
        "        return {'recon_loss': recon_loss}\n",
        "\n",
        "\n",
        "class VariationalAutoEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A basic feed forward classifier architecture with configurable dropout and\n",
        "    layer-wise normalization with ~*~ variational inference ~*~.\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, beta=1, dropout=0, norm='none'):\n",
        "        \"\"\"\n",
        "        An MLP variational antoencoder.\n",
        "        \"\"\"\n",
        "        super(VariationalAutoEncoder, self).__init__()\n",
        "\n",
        "        self.encoder = LinearLayers(layers=layers[:-1], dropout=dropout, norm=norm)\n",
        "        self.mu = LinearLayers(layers=[layers[-2], layers[-1]], activate_final=False)\n",
        "        self.logvar = LinearLayers(layers=[layers[-2], layers[-1]], activate_final=False)\n",
        "        self.decoder = LinearLayers(layers=layers[::-1], dropout=dropout,\n",
        "                                    norm=norm, activate_final=False)\n",
        "        self.criterion = torch.nn.MSELoss(reduction='sum')\n",
        "        self.beta = beta\n",
        "\n",
        "    def embed(self, X):\n",
        "        h = self.encoder(X)\n",
        "        mu = self.mu(h)\n",
        "        logvar = self.logvar(h)\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.rand_like(std)\n",
        "        z = mu + (std * eps)\n",
        "\n",
        "        return z\n",
        "\n",
        "    def decode(self, z):\n",
        "        x_prime = self.decoder(z)\n",
        "        return x_prime\n",
        "\n",
        "    def forward(self, x, fingerprint=0, compound=0, line=0):\n",
        "        mu, logvar = self.embed(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_prime = self.decoder(z)\n",
        "        return {'z': z, 'x_prime': x_prime, 'x': x, 'mu': mu, 'logvar': logvar}\n",
        "\n",
        "    def loss(self, outputs):\n",
        "        recon_loss = self.criterion(outputs['x_prime'], outputs['x'])\n",
        "        kl_div = -0.5 * torch.sum(1 + outputs['logvar'] - outputs['mu'].pow(2) - outputs['logvar'].exp())\n",
        "\n",
        "        # Apply beta scaling factor\n",
        "        kl_div *= self.beta\n",
        "\n",
        "        return {'recon_loss': recon_loss, 'kl_div': kl_div}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zYlz4bq9Zhrm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_VAE = VariationalAutoEncoder(layers=[20530, 100, 50], dropout=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6Vo5rDGZwHe",
        "colab_type": "code",
        "outputId": "d49363a0-6238-4f6f-d45b-1835e4ee46ff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 595
        }
      },
      "source": [
        "model_VAE"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VariationalAutoEncoder(\n",
              "  (encoder): LinearLayers(\n",
              "    (dropout): Dropout(p=0, inplace=False)\n",
              "    (activation): ReLU()\n",
              "    (model): Sequential(\n",
              "      (0): Linear(in_features=20530, out_features=100, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "  )\n",
              "  (mu): LinearLayers(\n",
              "    (dropout): Dropout(p=0, inplace=False)\n",
              "    (activation): ReLU()\n",
              "    (model): Sequential(\n",
              "      (0): Linear(in_features=100, out_features=50, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (logvar): LinearLayers(\n",
              "    (dropout): Dropout(p=0, inplace=False)\n",
              "    (activation): ReLU()\n",
              "    (model): Sequential(\n",
              "      (0): Linear(in_features=100, out_features=50, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (decoder): LinearLayers(\n",
              "    (dropout): Dropout(p=0, inplace=False)\n",
              "    (activation): ReLU()\n",
              "    (model): Sequential(\n",
              "      (0): Linear(in_features=50, out_features=100, bias=True)\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=100, out_features=20530, bias=True)\n",
              "    )\n",
              "  )\n",
              "  (criterion): MSELoss()\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLdWpLFFZ7-D",
        "colab_type": "text"
      },
      "source": [
        "# Step 1.3. Optimizer for the VAE"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DU04ttLZ6pp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "The loss was already defined in the VAE, we are only adding the Adam optimizer\n",
        "\"\"\"\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the optimizer, learning rate \n",
        "optimizer = optim.Adam(model_VAE.parameters(), lr=0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MAbix75NaNem",
        "colab_type": "text"
      },
      "source": [
        "# Step 1.4. Calculate the VAE training loss and the valid loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AU1Y_uXaRc0",
        "colab_type": "code",
        "outputId": "912e2c57-1685-4411-bb98-5e03556980d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        "all_training_losses = []\n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs): \n",
        "      for i, (inputs, labels) in enumerate(train_loader, 0):\n",
        "\n",
        "#pdb.set_trace()\n",
        "        # forward propogation\n",
        "        outputs = model_VAE(inputs)\n",
        "        \n",
        "        # calculate the loss\n",
        "        losses = model_VAE.loss(outputs)\n",
        "        loss = losses['recon_loss'] + losses['kl_div']\n",
        "# pdb.set_trace()\n",
        "\n",
        "        #\"ajouter la loss a la fin de liste de toutes les loss (all_losses) avec .append /.detach() « detache » ton tensor torch du graph de computation / .numpy() convertit le tensor en numpy array\"\n",
        "        all_training_losses.append(loss.detach().numpy())\n",
        "\n",
        "        # backpropogation + update parameters\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        cost = loss.item()\n",
        "        if i % 1000 == 0:    # print every 1000 iterations\n",
        "            print('Epoch:' + str(epoch) + \", Iteration: \" + str(i) \n",
        "                  + \", VAE training cost = \" + str(cost))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0, Iteration: 0, VAE training cost = 38164588.0\n",
            "Epoch:0, Iteration: 1000, VAE training cost = 8.219982496040565e+28\n",
            "Epoch:1, Iteration: 0, VAE training cost = 1.1815930457537686e+29\n",
            "Epoch:1, Iteration: 1000, VAE training cost = 2.5292516978761753e+29\n",
            "Epoch:2, Iteration: 0, VAE training cost = 1.5695543417874415e+29\n",
            "Epoch:2, Iteration: 1000, VAE training cost = 1.8199817197160077e+29\n",
            "Epoch:3, Iteration: 0, VAE training cost = 9.675532960749765e+28\n",
            "Epoch:3, Iteration: 1000, VAE training cost = 1.0626142500331535e+29\n",
            "Epoch:4, Iteration: 0, VAE training cost = 1.189247812927841e+29\n",
            "Epoch:4, Iteration: 1000, VAE training cost = 1.0079795865882304e+29\n",
            "Epoch:5, Iteration: 0, VAE training cost = 7.807995688288645e+28\n",
            "Epoch:5, Iteration: 1000, VAE training cost = 1.4551110957316336e+29\n",
            "Epoch:6, Iteration: 0, VAE training cost = 2.40062444629975e+29\n",
            "Epoch:6, Iteration: 1000, VAE training cost = 1.843723700550624e+29\n",
            "Epoch:7, Iteration: 0, VAE training cost = 1.1383169959627622e+29\n",
            "Epoch:7, Iteration: 1000, VAE training cost = 4.271387661752648e+29\n",
            "Epoch:8, Iteration: 0, VAE training cost = 5.665654465456374e+28\n",
            "Epoch:8, Iteration: 1000, VAE training cost = 7.823270654914135e+28\n",
            "Epoch:9, Iteration: 0, VAE training cost = 1.3160782985048642e+29\n",
            "Epoch:9, Iteration: 1000, VAE training cost = 1.908858168080889e+29\n",
            "Epoch:10, Iteration: 0, VAE training cost = 1.2097516670651534e+29\n",
            "Epoch:10, Iteration: 1000, VAE training cost = 4.697900846595194e+28\n",
            "Epoch:11, Iteration: 0, VAE training cost = 2.6373808566023975e+29\n",
            "Epoch:11, Iteration: 1000, VAE training cost = 1.0150586028407113e+29\n",
            "Epoch:12, Iteration: 0, VAE training cost = 1.6005741505034673e+29\n",
            "Epoch:12, Iteration: 1000, VAE training cost = 1.1170758859701442e+29\n",
            "Epoch:13, Iteration: 0, VAE training cost = 1.3004398041075228e+29\n",
            "Epoch:13, Iteration: 1000, VAE training cost = 1.0953032264062144e+29\n",
            "Epoch:14, Iteration: 0, VAE training cost = 1.5866631922128892e+29\n",
            "Epoch:14, Iteration: 1000, VAE training cost = 2.014794637601785e+29\n",
            "Epoch:15, Iteration: 0, VAE training cost = 2.15642823094533e+29\n",
            "Epoch:15, Iteration: 1000, VAE training cost = 8.42201855680388e+28\n",
            "Epoch:16, Iteration: 0, VAE training cost = 1.244088182656758e+29\n",
            "Epoch:16, Iteration: 1000, VAE training cost = 2.100081331861048e+29\n",
            "Epoch:17, Iteration: 0, VAE training cost = 1.0563769483825792e+29\n",
            "Epoch:17, Iteration: 1000, VAE training cost = 1.6449789403312092e+29\n",
            "Epoch:18, Iteration: 0, VAE training cost = 9.242899966734738e+28\n",
            "Epoch:18, Iteration: 1000, VAE training cost = 3.57818392994584e+29\n",
            "Epoch:19, Iteration: 0, VAE training cost = 6.825499785741242e+28\n",
            "Epoch:19, Iteration: 1000, VAE training cost = 1.059054057941718e+29\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2T4Jm9OPaTVS",
        "colab_type": "code",
        "outputId": "16f10fd3-7e3f-4717-977e-93267f40e564",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        }
      },
      "source": [
        " # Compute validation error (we don't use the backpropagation and the update of the parametres in the validation error step)\n",
        " all_valid_loss= []\n",
        " num_epochs = 20\n",
        " \n",
        " for epoch in range(num_epochs): \n",
        "      for i, (inputs, labels) in enumerate(test_loader, 0):\n",
        "        outputs = model_VAE(inputs)\n",
        "        \n",
        "        # calculate the loss\n",
        "        valid_losses = model_VAE.loss(outputs)\n",
        "        valid_loss = valid_losses['recon_loss'] + valid_losses['kl_div']\n",
        "        #pdb.set_trace()\n",
        "\n",
        "        #Save all the training losses in a list.append /.detach() « detache » ton tensor torch du graph de computation / .numpy() convertit le tensor en numpy array\"\n",
        "        all_valid_loss.append(valid_loss.detach().numpy())\n",
        "\n",
        "        # print statistics\n",
        "        cost = valid_loss.item()\n",
        "        if i % 300 == 0:    # print every 300 iterations\n",
        "            print('Epoch:' + str(epoch) + \", Iteration: \" + str(i) \n",
        "                  + \", VAE valid cost = \" + str(cost))\n",
        "            \n",
        "    #print(np.mean(all_valid_loss)) \"doesn't seem to work\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch:0, Iteration: 0, VAE valid cost = 1.4646668043097204e+29\n",
            "Epoch:0, Iteration: 300, VAE valid cost = 1.3405686799796855e+29\n",
            "Epoch:1, Iteration: 0, VAE valid cost = 9.288649308747483e+28\n",
            "Epoch:1, Iteration: 300, VAE valid cost = 8.484431241188079e+28\n",
            "Epoch:2, Iteration: 0, VAE valid cost = 1.7999488744116968e+29\n",
            "Epoch:2, Iteration: 300, VAE valid cost = 1.8633655339101532e+29\n",
            "Epoch:3, Iteration: 0, VAE valid cost = 1.5667750402176134e+29\n",
            "Epoch:3, Iteration: 300, VAE valid cost = 2.6835174326667374e+29\n",
            "Epoch:4, Iteration: 0, VAE valid cost = 1.2046695507036188e+29\n",
            "Epoch:4, Iteration: 300, VAE valid cost = 2.7471248757711017e+29\n",
            "Epoch:5, Iteration: 0, VAE valid cost = 2.118900151189943e+29\n",
            "Epoch:5, Iteration: 300, VAE valid cost = 1.275276107619574e+29\n",
            "Epoch:6, Iteration: 0, VAE valid cost = 9.02345065180249e+28\n",
            "Epoch:6, Iteration: 300, VAE valid cost = 1.3464698435840091e+29\n",
            "Epoch:7, Iteration: 0, VAE valid cost = 1.2437621504747806e+29\n",
            "Epoch:7, Iteration: 300, VAE valid cost = 2.472741404911586e+29\n",
            "Epoch:8, Iteration: 0, VAE valid cost = 8.067838237168767e+28\n",
            "Epoch:8, Iteration: 300, VAE valid cost = 1.2941015382615448e+29\n",
            "Epoch:9, Iteration: 0, VAE valid cost = 1.303244700903688e+29\n",
            "Epoch:9, Iteration: 300, VAE valid cost = 9.086364851507169e+28\n",
            "Epoch:10, Iteration: 0, VAE valid cost = 7.171103343370168e+28\n",
            "Epoch:10, Iteration: 300, VAE valid cost = 1.1069922168192727e+29\n",
            "Epoch:11, Iteration: 0, VAE valid cost = 1.8862826117675417e+29\n",
            "Epoch:11, Iteration: 300, VAE valid cost = 5.5327804841492335e+29\n",
            "Epoch:12, Iteration: 0, VAE valid cost = 1.3331600425467003e+29\n",
            "Epoch:12, Iteration: 300, VAE valid cost = 8.395970927757668e+28\n",
            "Epoch:13, Iteration: 0, VAE valid cost = 6.608528768739203e+28\n",
            "Epoch:13, Iteration: 300, VAE valid cost = 3.5228393059238825e+29\n",
            "Epoch:14, Iteration: 0, VAE valid cost = 2.6312510360129734e+29\n",
            "Epoch:14, Iteration: 300, VAE valid cost = 1.5025992886412345e+30\n",
            "Epoch:15, Iteration: 0, VAE valid cost = 4.612487970703509e+29\n",
            "Epoch:15, Iteration: 300, VAE valid cost = 7.245637870279244e+28\n",
            "Epoch:16, Iteration: 0, VAE valid cost = 4.345308942150259e+29\n",
            "Epoch:16, Iteration: 300, VAE valid cost = 1.280235159110565e+29\n",
            "Epoch:17, Iteration: 0, VAE valid cost = 1.4635986050112952e+29\n",
            "Epoch:17, Iteration: 300, VAE valid cost = 2.757936450491643e+29\n",
            "Epoch:18, Iteration: 0, VAE valid cost = 1.1504901233876443e+29\n",
            "Epoch:18, Iteration: 300, VAE valid cost = 9.554928443143757e+28\n",
            "Epoch:19, Iteration: 0, VAE valid cost = 2.665725066916559e+29\n",
            "Epoch:19, Iteration: 300, VAE valid cost = 7.795956959413865e+28\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kc_VB-1da3gP",
        "colab_type": "text"
      },
      "source": [
        "# Step 1.5. Visualize the VAE loss history"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1B1DxNbsa9xY",
        "colab_type": "code",
        "outputId": "54c8328b-bd5a-4254-9ff4-f73334bb1baa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(all_training_losses)\n",
        "plt.title(\"VAE Training loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6q8EXGBSa--e",
        "colab_type": "code",
        "outputId": "272724bd-6fbf-4237-9ebf-20561a0b2a49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "plt.plot(all_valid_loss)\n",
        "plt.title(\"VAE Valid loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPw9CXm7bHBF",
        "colab_type": "code",
        "outputId": "b789cd9a-761a-4073-8d4c-918a5ed01331",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        }
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(all_training_losses)\n",
        "plt.plot(all_valid_loss)\n",
        "plt.title(\"VAE Training loss VS Valid loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWoAAAEICAYAAAB25L6yAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2dd5xdRfn/308aoYRQstIhCHyBUAQMxe8XUBGlKijqF/yKWFF/IKCoFKWIkSYgRVrAAKG3UAMJCWkkQMKmt03flE02uymb3c323fn9cc6Gm91bzr33lDn3Pu/Xa5N7zzl3zjOnfGbmmZlnxBiDoiiKYi89ojZAURRFSY8KtaIoiuWoUCuKoliOCrWiKIrlqFAriqJYjgq1oiiK5ahQKzkjIo+JyE1+H5ulDQNFxIhIL7/TthkR+amITE74Xi8iX/RybJd9RXn94oYKtQWIyCgRuS3J9gtEpLLzJRKRr7kv1XVdjut82eq7/P1vkjTnJ+xvF5GmhO83ZmO3MeY3xpi/+32srXi5TyKyv4i8LiIbRGSLiMwTkZ8m+c1+ItImIock2feGiNyTjW3GmF2MMcuzypASG1So7eAZ4MciIl22Xwo8b4xpc79fBmwCfpIind3cF7bz7+WuBxhjjurcD3wEXJlw/O2dx2kNKyle7tOzwGrgIGBPd9/6rgkZYyqAD9392xCRPYBz3XMpCqBCbQtv4rzUp3VuEJHdgfOB4e73nYHvA1cAh4nIYD8NSKiV/0JEVgHj3O2vurXFLSIySUSOSvjN0yIyxP38NRFZIyLXikiViKwTkZ/leOyeIvKOiNSKyGciMiRV0z1JPvYVkbdFZJOILBWRXyXsO0lESt1014vIfe72viLynIhsFJEa95x7JUk+430CTgSeNsZsNca0GWNmGmPeT2HuM3QRauBiYIExZq6IXC8iy0SkTkQWiMh30+TbiMih7uc93WtQKyLTgG619jTpBHn9lBxRobYAY0wj8Arb15R/CJQZY2a7378H1AOvAqNxatdB8FXgSOAs9/v7wGHAF4AZwPNpfrs30B/YD/gF8LArZNke+zCw1T3mMrLL60vAGmBfnILtdhE5w933APCAMWZXHPF6xd1+mWvLAThC/BugsWvCHu/Tp25eLhaRAzPY+gYwQEROTdh2KZ/XppfhFAr9gb8Bz4nIPhnSBOf6NQH7AD93/7wS2PVT8sAYE8gfMAyoAuZ5OPY3wFxgFjAZGJSw7wZgKbAIOCsoe6P+A04FaoC+7vcpwO8T9o8F7nc/XwJUA73d7wMB4/4+8e/IDOecAPyySxpfTHP8bu4x/d3vTwND3M9fw3k5eyUcXwWcks2xQE+gFTg8Yd8QYHIKmzrt7oUjFO1Av4T9d+DUcAEm4QjegC5p/Bz4GDjWh/u0O3AnMN+1ZRZwYpr0ngSGup8PA1qAL6Q4dhZwgfv5p4nXxL0GhyZcvyMS9t1uy/XTv9z+gqxRPw2c7fHYF4wxxxhjjgPuBjqbVINwmoJHuWk9IiI9A7A1cowxk4ENwIVuB9NJwAsAInIA8HU+r82+BfQFzuuSzABjzG4JfwtzMGV15wcR6Skid7rN71qgvPM8KX670XzuTwdoAHbJ8tgSHNFYnbAv8XM69gU2GWPqEratxKm1g1Nz/y+gzG2en+9ufxanlfKSiKwVkbtFpHeyE6S7T+7+zcaY640xRwF74Yjrm0n82p08A/xARPri1KZHG2OqAETkJyIyy3Un1ABHk/rad5Ls+q3M8JtOAr9+Sm4EJtTGmEk4HV/bEJFDxOk5ny4iH4nIEe6xtQmH7YxTwgNcALxkjGk2xqzAqVmfFJTNFjAcp1n9Y5wXtrMT6lKce/WOiFQCy3GEOgj3R2I4xR/h3IMzcZq2A93tqUTHD6qBNmD/hG0HePztWmAPEemXsO1AoALAGLPEGHMJjhvnLuA1EdnZGNNqjPmbMWYQ8N84PudUHbaQ+j5thzFmA3APjgDukSKtyTjvyQVues8AiMhBwBPAlcCexpjdgHlkvvad1y/xmmVywXQS1vVTsiRsH/VQ4HfGmC8DfwQe6dwhIleIyDKcGvVV7ub92L5msIbPS/dCZDiOKP6K7Xv9L8Npch6X8HcRcK6I7BmgPf2AZmAjsBNOEzpQjDHtwAjgVhHZyS3MPb30xpjVOE3wO9wOrmNxaoHPAYjIj0WkxBjTgeO+AOgQka+LyDFua60Wx3XQkeZUqe4TInKXiBwtzlC9fsBvgaXGmI0pbDZuenfhuJbecXd1Vliq3XR/hlOjznQNul6/QXgs0EO8fkqWhCbUIrILTmn7qojMAh7H6ewAwBjzsDHmEOA64K9h2WUTxphynBdlZ+BtABE5BWeo18PGmMqEv7dxWhiXJCRRI9uPo/5DniYNx2n6VgALcDrKwuBKnBp8JU6z+kWcAsMLl+DU/NfidNbdYowZ6+47G5gvIvU4HWMXG6eDcG/gNRyRWQhMdM+blGT3KYGd3PPW4LR8DgK+k8Hm4Tg115eNMc3uORYA9wKf4AzvOwbHH+6FK3HcSJU4LsinPP4OQrh+SvaIU6AHlLjIQOBdY8zRIrIrsMgYk7bXWkR6AJuNMf1F5AYAY8wd7r7RwK3GmE8CM1qxDhG5C9jbGBPUSBdFsZrQatSuH3qFiPwAQBy+5H4+LOHQ84Al7ue3gYtFZAcRORinV3xaWDYr0SAiR4jIse4zchJO8/uNqO1SlKgIbPaZiLyIMwxrgIisAW4B/g94VET+CvTGGbM5G7hSRM7E8W1txvWpGWPmi8grOM3uNuAK1wenFDb9cNwd++I0++/FGemiKEVJoK4PRVEUJX90ZqKiKIrlBOL6GDBggBk4cGAQSSuKohQk06dP32CMKUm2LxChHjhwIKWlpUEkrSiKUpCISMoZpOr6UBRFsRwVakVRFMtRoVYURbEcFWpFURTLUaFWFEWxHBVqRVEUy1GhVhRFsRwVakt4e/ZatjS2Rm2GoigWokJtAcuq67nqxZlc+8qsqE1RFMVCVKgtoLHFCQi4tqYpYksURbERFWpFURTLUaFWFEWxnIxCLSKHu0vWd/7Visg1YRinKIqieIieZ4xZhLPqNe4qwxXoskiKoiihka3r4xvAMmNMynB8iqIoir9kK9QX46xlpyhKFzZvbaG9Q5e2U/zHs1CLSB/gO8CrKfZfLiKlIlJaXV3tl32KEgu2NLRy/N/HcNeosqhNUQqQbGrU5wAzjDHrk+00xgw1xgw2xgwuKUm6moyiFCw1jS0AjJpXGbElSiGSjVBfgro9FEVRQseTUIvIzsA3gRHBmqMoiqJ0xdPitsaYrcCeAduiKIqiJEFnJiqKoliOCrWiKIrlqFDnQnsrjLoBGjZFbYmiKEVAvITaGCh9Clobo7Vj/hvw6SPwwU3R2qEoSlEQL6Fe9B68ew18eFu0dnS0u/+3RWuHoihFQbyEurnO+b9hY7R2KIqihEi8hFpRFKUIUaFWFEWxHBVqi9C4a/HH6F1UAkCF2gJEumxo2gIbl0Vii5IbQtebqCj+oUKdEwHXmv5zFjx0QrDnUBQlNqhQ50O3qrBPVC8MJl1FUTjvwY/4+dOfRW1GVngKymQdRv2AiqLkxvy1tcxfWxu1GVkRsxq1+gEVRSk+YibUiqIoxYcKdS6o60VRlBBRoc4LdcUoihI8KtQ5oTVqRVHCQ4U6H4IanqcoipKA18VtdxOR10SkTEQWishXgjZMURQlCtraO2hsaY/ajO3wWqN+ABhljDkC+BKgMzIUJQnazxx/fvb0Zxx586iozdiOjBNeRKQ/cDrwUwBjTAvQEqxZmdC3QbEL9YIVDh8t2RC1Cd3wUqM+GKgGnhKRmSLypIjs3PUgEblcREpFpLS6utp3Q92TJN3c0tZBTUPEZYeiKEpAeBHqXsAJwKPGmOOBrcD1XQ8yxgw1xgw2xgwuKSnx2cz0/Oa56Rx325hQz1mMLFlfx5E3jaKiJuI1KyPms/JNjFmwPmozlCLCi1CvAdYYY6a631/DEW5rGFdWFbUJRcHzU1fR2NrO6HmVUZsSKT947BN+Nbw0ajOUIiKjUBtjKoHVInK4u+kbwIJArbId7TFSFCVEvEbP+x3wvIj0AZYDPwvOpDihPUiK/cxeXcNeu/Zl7/59ozZFyRFPQm2MmQUMDtiWGKE1aiU+XPDwFPr06sHiIedEbYqSIzozMR+0Qq34zOAhY/nJsGm+p9vS1uF7mkp4xFOo1UesWIoxsHpTQ86/31DfzKTFAQ1vVWJLzIS6sKuwJiYFUDysjIaKmkZOu3s8C2K2gohiNzET6sIkLitY6+w776zKo1atKF1Roc6FmNR8FUUpDFSo80KrmLbS3mE4+faxvDmzImpTFCVvVKiVgqSxtZ31tc385Y25UZuiKHmjQq0oimI5KtRK1sRldIqiFAr2CXVzPdzaH6YOjdoSpQtxGZ2iKIWGfUJd74aP/PSRNAdFXaOL+vyKohQT9gl1OmwZyNvZ9LfFnhhijOHJj5azsb45sPQVpVCIl1Bbhwp1rsxZs4UhIxdy7auzAz2PaGGqFAAq1EoktLY7QYLqmtoitkRR7EeFWlEUxXJUqBVFUSzHXqFW36J16C1RlGiwV6hjwBszK9i8tSVqMxRFKXA8CbWIlIvIXBGZJSLRL79sydCrxtZ2Pl62MWozYk1Qw+jCfkK0taEEidfFbQG+bozZEJglscKOgiLOhCVsqp9KIaCuj7xQGVAUJXi8CrUBPhCR6SJyebIDRORyESkVkdLq6jzWfLPErZET9VXQsjVqKwInzrdIUeKIV6E+1RhzAnAOcIWInN71AGPMUGPMYGPM4JKSEh9Ms7i2mkqp7jkMnjwz++Ri4kqx+I4oii8sqqyL2oSkeBJqY0yF+38V8AZwUpBG5czYv8H420M7nUG6i2zVgpzT0+nO0bJgbS1jF6yP2gwlQoZ/Uh61CUnJKNQisrOI9Ov8DHwLmBe0YTkx+T6YeFfUVuRMMQYSCirHuVzKcx/8iF8O92tQk385W1pVx9n3T2JLY6tvaSrxwkuNei9gsojMBqYBI40xo4IzqfjEqjjjPOuwD6888OFSyirrmLCoKmpTlIjIODzPGLMc+FIItmyP1W6A4itMFEWJDvuG53lqs9ohlHZYoShKoWOfUG8jSY3a6lp28RCXUSqKUihYLNTxoJj6/7ScTE2uz8HIOetYsaHwx94r+aFCrQTCmAXrue61ORmPK6aCLhlXvDCDb9w7IWozFMtRoVYC4VfDS3m5dHXK/YVWO88nPx1FXlgpmSkOoS6fAnceBE1borZEURQlaywU6gCqFxPugKYaWBfsQqq+06axrpX4UrmliTE609MXLBRql2RtSVscmq4dzhTyAFk7I8jUc8aW26DYzUWPfsyvfJvpWdzYK9RpscPBaSyxIyw0FomSDRU1jVGbUDDEVKi1SlcoBHYn3YQ7Ogz/GrOY+ua2oM6kKIETL6HWGl3BENad3NrSzgMfLuHuUWUhnVFR/CdeQq0oOdLU2h61CYqSM/YJtfZUKZYyfeXmogxF29zWrgVdxNgn1NuIh5ujGF/cQs/xkvV1fDC/crtto+ZVctGjH/PitNSTeAqV/7lzHEfcFGBkYyUj2axCHhIByoBfolqE4gwBFZ0WXstv/msSAOV3nrdt2+pNDQAsr66PxKYo2VCv4/mjxt4adQw6Du2TmPgQ9FA/WyP8GWN4furKSFwJm7a2MPD6kbw/d13o5/abO98v69bqKWTsFWpFiRFeC57R89fzlzfmcc/oRQFb1J3F652FW5/6uDz0c/vNYxOXcfmz06M2IzTsE2ovTWELm8uBUCz5LCI6x3NvarDLndDRYbjtnQWs2tgQtSlKEjwLtYj0FJGZIvJukAYlnDHjtua2dkbMWBOOOUVAbVPhLp7qW/eEP8lYx8LKWoZNWcFvny+eWmqcyKZGfTWwMChDcuFfY5bwh1eiCLSU4+u66lPYuMxfU3xi2opNHHvrB4wr0yA6ycjWpR63xlCnvXGzu1jwJNQisj9wHvBksOZkR1VdUzgn+uRhWPlxt81Zx/oYdhY8dEK3zTb0m85YtRmAqcs3ZTzWz5dZdUFRMuO1Rn0/8GegI9UBInK5iJSKSGl1dbUvxlnD6BvhqXM+/67VjrwJumwqtls0r2IL67ZoEKRCJaNQi8j5QJUxJq3zyhgz1Bgz2BgzuKSkxDcD/cXft7fYoud1YkMLICpsLQDOf2gy/33nOG8H+5CHqromTvrHWJa4I0mUYPFSo/4f4DsiUg68BJwhIs8FZ1IAb0IxK4sSKfXNbaFF7stUiPj5FoxZsJ6qumaGTSn3MdXUdI5KKcYJR+BBqI0xNxhj9jfGDAQuBsYZY34cuGUxEVdba1hxp6ahhS2N8R+FcvQtozn6ltFRmxF7lm+oZ9iUFUU1djoRC6eQKwocd9sYYPtp3PlgXXlqnUHxoBhj60CWE16MMROMMecHZUwWluT+07G3wn2DfLOkUMjm+fd11EeRvXfxaCcqtmHfzMRE1i+A6U9//r3THbLgLXj7d1knd8d7ZTD5X1Bb4Y99mWjZCnX5xCOIQMVSKElDSxut7f7ZE7Zn67Xp/kyM8hpDJCaeu24UWbkZG6wS6oaWNjZubf58w6NfgXeuTn7wjOGpE1o3G575NrQ1b7d57totPliZBcPOhnsPD/ecATHo5tEMm7IiajMio5DWi0xW2BRQ9goSq3zU335oMr03LGTUDnkm9O7voWI6VM6F/Qf7Ytv2eKx3VM4J4NyKjcRB53IpbP45OtMSZloHDwOratTLqrci2268/4++BPBQ2RpOU1H84OHxdoU8KNa3zSqh3g5f22I+i75fPWAL34Fb+9N7S/G5FIqtE7FwCast4f95fvfiTDbUN2c+0AKscn3EjbQzE9cvyJzAvNcB6Fs9F9jdH6Nizg8f/4TTDh0QtRkp0QKmcHhn9lp227E3f7/w6KhNyYgKdRBUL3I6QmNENi4cP9w9qRpM01ZsYtqKzIGhwiYOPmilcLHX9RFn6tIvdTSvIuTRJ1kgBSJJtld8o7TPj1ZBa5sTn23Gys35J5YHm7a28PjEZQU/EcY6oU7f4RdTEamvgrL3tn3tOswtiE5OP1haVceWhvhP47aJKIfB+XnucnclmEUhBGWq3NLEr58tTbrvj6/O5o73y5i5uiantOMyGMA6od7GxqX5p+G1lO1ohw9ucgTVW8LZ2fHsd+GlS5LssLvgOfO+SVz4yBTf0ntzZgWvlq72LT3Ff2ysmd49uoxl1VuT7qtzVyVq83Eylo3YK9Rt+SwK4Apg5Wxo91AjXDYePn4Q3rkmq7N4DnO6aXlW6X5+gugfvhUbkr8guXDNy7P402vxHFte6BNCYuPyiv6ViIRYdyZmfLhGXgvVixOOT8Ei1y3R4Vczf/sztXcYeiZuiNnDdtTNowJLOy5NT6U48Po03jdmMYsr63js0i8Hak8n9tao/WLtjLTVobEL1kPpfzwlNXJO+k7CVDS3pVwYx8F08Nueb7NrR/6djM9+Us4yn2P2bm1p3+67HxX92NTgFCUJD364hFHz84njkx2FL9TVi9LuHjLSw3hnl8lLN+RkQkpdcwuQndZN47reL3F1w79zSj+Rm96az4X/zt6vbIGXxVei9rVmOn1bh2HUvM9f9EE3j+J3L85MkZbfKxMpnXS9tLZWH6xzffh+oZproT6YNRy/1aOUUh9eot5bnZr6jvizWG9dHiuKFLovNl9SiWa21+2d2Wt5Z/babd8bWtq3+x4E2d7aP782OxA7/KTQKhipKPwaNUCzxyFESz6AVVM9J3tAj2r2Wfdh9x0Z3tptz1bdegB2WZUkjU7KpzidnUqkRFl+RRW575VSf0LDhkHUFYzJSzb42vHeleIQ6mz46J40O12JTSjGd2jOYxZde0vmY54+F569MPdzKEpMMMbQ3Nae+UAL+fF/pvL1eyYEln68hLpLsblrazAujcxk195KOYyvS35KOqLKT3QUS9O10AiiBvv4pOUc/tdRbNq6fQUmsePZ78clLo9fRqEWkb4iMk1EZovIfBH5WxiGeeG3K3/v8cgQbkdr/v7lAzpCWnnGAqJuqkZFsebbC2/McJ7/qjp/+moKCS816mbgDGPMl4DjgLNF5JTgTPIuqv3aNgZnRhLS1v5G/DLhS/q38bz1j3uLrqfkTFBFc1xqYNlSrAVIW3uGobOWkFGojUPnwNze7l9gz2sucS++3eNjyvv+KABrMrNNvJeM8fybMze94PieldhQUEtxFZC/Kd+cxKXD1JOPWkR6isgsoAoYY4zpNjRCRC4XkVIRKa2uDtfXenWvETn/NowXMKmP2nSQqebd2Bp+x0rhyJHSlbiUNbmUIzHJWs54EmpjTLsx5jhgf+AkEekWadsYM9QYM9gYM7ikpMRvO0PEnls+Ymbx+KwVJS4FSRRkNerDGFMDjAfODsac7Ag7PKjnkt6nJ64109TzAiBurfC42asUBl5GfZSIyG7u5x2BbwKZlia2C7/frqTppRZnfbeVTgpF6KOK1VJI/vVs8FKj3gcYLyJzgM9wfNTvBmtWKpI/HN18wPnUaJeMhlcuy/33XjHkbmd7G5Q+5fwfAfm+LEPeXUBTwP73oN5nbZ57Y+6a3AOMdYu/odc8c6wPY8wc4PgQbAFC9BBvXgm7H5R834I3PSeTIvJDLhZ1TyVVMp89AaOud2Y2nvxrX84VJk9OXsG6LTpWtpBZWh38yi9QPDXseMxMXDUVJqWb2p0D7/8565/4Gjs5Hy1vcKetN+a2/FAywn7g2zqC9b+HXQvz6goolNqhbfmwzR6/sS56XlKGfcv5/4fP5pVMss7H3O5vElFL+6TY/xR16nShP/D5UgwVuIaWzC61YrgONhEPoU6JSfg3juSqisHlOOxOorjcu0IvwBasrd32edDNo+ndM7oM66o/3YmH68MSfB2e5yGtjMMPY6weusKLP2xpaGXg9SOT7ntp2iqq65q3fX9+6qqU6Vz76vaxp1szLBYbxKNXSLM//SbmNepw2a2lEjqOCbbdt3ll5mO03ZmRYrlES1Msu7Z6UwPXj5jLCQd+vur7iBnhTaAqlusfFtbVqAOZxFLrzOd/ts+deSXzlyU/hIld0+i016dx1A8c6+GgzOcMEn0J7aetw7lJXUOGQnzcTZ1EVc+urmu2ZlSJdUKdCynjPaf9UY43YMWk3H6XjGyaesmi7WlLMXTUf+oQ5KOXzasZ5N048R9jeWFaandRmMRLqLsIm1j7znh4jLM95NGvwIpJVNQ0xiY0YzqiFLxEv61X8hWmETPiEaUtSvK7xsEUHR8vCzeUciriJdQxoasIJY+el0PCb1/F/9w5jpFzOxdB9e/hzMacaeV5LD/W9bwhNy1nrtrMif8YG7hwds3VH14JZqHYTEtXWVuXUbLCOqEOO9CSb1qXUNsfV1blU6JdME5Nes3mxmDSx5s35qMlG/I+T3NEAafKKp0Zc9NW+FfYZIPfo11+9ETyxZhzHvipyr49llwP64Q6LSmeolx81LVNrekPqFmdfLvpWlvuTnlgqxE7ZysE1/SERU7M8pqGDPchCW/NquCom0fREoHYpxIy9V1vjwq+v1gn1GGJ0Gflm9MfUP6Rp3SCFItU40q3tToKYNxpZW32MT+GjFzI1pZ2ahpSr+Luu3AWwLXuxA8RzZRELqdIdYlNis9hYEsBbJ1Q+0HwK6N8fvPenbPO/RTFi5z+nKs3NWRdkDw0bimH3PhePkZFysqNW1lUGU5AoESKeQJPY0v4KxFFQVVdE2WVtZkPDICYC3XyKeSBt4gzVEm67t1NkrhCPLzXh9ZMSZqwF0moa2rltLvHc8OIuR6O3p72DjtqEZlIZuVX/zmBs+7PPISyWJrmgYV7Tfh8/kPeWp9+nCtKTrtrPGffH2xeUxFzoU7OLhuC6WEHoNqnNRMMZHoET6l8Pn0aXdqKiSMoOms5k5aEu35lLrw1K7sZc7m+uOtrm6x56YMmV09NVV32rqhl1f72ydhUiCbaElUHOMRNqD0+fWICbIo1eQktGpActDWyJ1vww1NXvmEr33tkyrZO1ShfjqtfmsWS9fm5KzbWN3PWv9LXpNfW5D9axiINCYTNOXTuZuLGN7y16nIpXKLoUI4C64Q69OF5KcniqZl8P7SE4BfdWs30vr9N2JDZxlQC/MCHS5ixqoaxC9b7Y1ueNLVm/8Il5u3dOetYlKfYpyPTlV6wLvcVTQqRxNbdC2mCQeXL/LXR+IzDxjqhzo3carB+iNT+Ug1jb8k7nWzwVJgVcBvfU80r5PL+50+X+pre0qo6nv2k3Nc0g8YYw9uz19Ia45mzb89eu913W9wwXha3PUBExovIAhGZLyJXh2FY0AiGXw4vpSPPjrMedH8oe3V4nKKcoyPx173csJYehxCmw5YHMRcSh07ZEjwnE15v+XkPTuamt+bnfb5kw8uCulKj56/nqhdn8tC4pQGdIfjnta4pmnVIM+GlRt0GXGuMGQScAlwhIoOCNct20j8tP112TThmLB3r4aDtba1vbmNLY2usK9x+DIWzZXxsKvLtuAp6uGCyAmezO669Koex8fmSzzD3bCeoRRFrJ6NQG2PWGWNmuJ/rgIXAfkEZdGQP7/6sfB7FM3rO4qc9R+X02wofOqWCJtWL+uW/j+FLf/sgZGuCx881HdKeJwt9v2/M4vxOFjNi0qjpxtfumZByX7IC/YEPlwRoTXKy8lGLyECcFcmTBxjIk2/0mM7tvf8TRNJJubX38Jx+t3pTg8+WhEfXmlqu75ZXl5FXl0QuNdxshSEfHclF4J+avCKPM8aLxHfC70mctk0KjWJClWehFpFdgNeBa4wx3bpaReRyESkVkdLq6tzG7h4iazMf5DN7dGQfnGfS4vyDEoVFSjHr8vBnK5RfvPG9yCbGJHtx41Cbm1cR3siQzvvZ2BJOM/20u8d3OX/u2OSWsuW58iTUItIbR6SfN8aMSHaMMWaoMWawMWZwSUmJnzYGyiNN1yXdvu3+rJsTmi1+EkYtpK0j2t79dO9Q1O9Xsst/27tJFn8IiFHzKgHYUJ997O1c2U5gc7gBne667/x7SmBuo0mL7Z8Algwvo5WrYdAAABN9SURBVD4E+A+w0BhzX5DGZNaWrkfk/zrubZLfuNlr3NrP46d127ez+OCjbrZj3G1cRktkIttc5J7tLH7oU2H5jjtk7OXPUkR0TGCiK0Rbm9OMXvDhnqdfiDb/jD8YkB/4J8OmBZJu0HipUf8PcClwhojMcv/ODdiurMhpKa4MNLa2Q1vy6GxX9Hrb9/MFRWrPh2WOvyzwYnmqYxLz3dFh2OJxJp4v1ytPffSy2shlw6YVxApAqUjlFgnqabalGuNl1MdkY4wYY441xhzn/gUSXs2Wi7KNyYE2IAL1T3hN2Y9rXlXbxFUvzkwaRS3ICnu+rYFzH/yIL932QSTDyYLEEP279OfX4+cytLl1WSAzEwNiwh2BJp8xJnYejJzrhF9N9fD5UUZ0Jn3n+2W8PXst781dl/4HPpGs2e3lJUs8pLK2adtqL1U5rKHohe6OOnuFwAaiHt3x1JTyaA1Igwp1hAQZUOZmH2a1ecUP+Qm7MhNlJLSgiapimO15W9o6+NeYxRnjWSe6narrmgN7b6avCq7ilC+xFurOmBdxrafsKOH1yKfEvXi5vNxda0Bh14jS2ZxqV7612henbd+hV9fUmsWY8rxOHRu8Pgcvl67mgQ+X8NA47x2HTa0dXPXizBwty42m1naaAl+MJD29Ij17QZC7Op3QI7iYCJ14HEad3zlcBYq66ZorXuxOdszG+ma+PGQs15x5WLd9hkwjI3KjoaWNnfrk99r6UV74kbNmV/yyjZw4an6lD2fvzsJ1ySPxHXPraKJeS8OqGnU83/MiqSYlobOG2HkFohxJ4rW26qeN1e4Y5ffnehMOP56UQTeP9nCeEJ7JZJOOskyiM1Jdp7353Bk/CsXlSRZAMAZa203kqx7Fq0ad4mYEMTyvWJqpfrzUmVwQExdXc/vIhXmfJyjCKmBWbtzK3DXZjZ+3JV54Nni9mnOyvBZRsLQq/OniybBKqLOVjN4m9SrUSnr8bJVvq1GnSPPGEXMDD2SVbYEThjR3vR4b6lt4Msv4H7e/l1sBF3j+LKvIdBhDa3sHvXv66yQo32hHXB+rhDoXvt9zYtQmREtbM/TaIZJTdwpRuqFxYa1onk8LyEuhlcsiwVGyenMEER5zvAl+tF7/8PIsyjc2UH7neUn3vzmzgic+Wp7/iSLCKh91Lnyzx/RIzx/50mHjhqTdXdPQmnR88yula/I+dTcfdUi9iUmDMnX9nuG2JO7OO/RpgM9ALikbA2/MzG7BYCvI40Zkqvle8/KsWC/bFXuhhmBaYWtiEHMagPqqjIf8v+dnZDzGlpEAgZPEyFx91GH4ttO1ViZGGWAohJv9z9FlDLx+ZGxHE/lJQQh1EExZmjmuAgTTkZkVeT7F23Qgn/ZnTCZYpMJmIUiXxcsiDDCUrpDy63o+PH6ZPwn5zAcRdPBa5aPO5f4G5Xqw+N3tQvSWdjb9e4jQ1Noe+Kw/P+JRR3/V7GFLo7fAVEFhc4wNW7BKqHPhWz2j9VH/pte7kZ7fBjrfMxEn0FGy8aiBnDfLQnpc2XrmVnT3UwoEMk7Wj8IgDA0b4lOc7HxN1cIzNVYJdaYb3WFMaL6aYinj/Y7TEZRIN7c5NfVd+/ZO2uz2ItrpmtL5jE6JW4Ww6/jlBp+nR8c5hK6txMpH/Z7HGWBFhUUO1tI8ogGm0rrOeNE/fPxTjr3V+6K8mYR7+1EfOXYmhnDpw5hlmEs2ktmVa4GV6WfZpnvH+wuZtbomN2MsJVZC/W5IYTTjxLLqrdS7q3lEFjXNfdWGTfF/MdcLH5kCwOwkL96MVZv5eKmzfmXXvG9t9l5LnBlQ1DQ/hiuGcU9zsjONXQtSxMxIRVuHodqnULNVdU08PnE5Fz48xZf0bCFWQt3WHrM2ZghMX7mZW/IIadp1LHT2vzeMnh9cL/iKDd1dKZ268vuXZ/OjJ6cm/d21r872fI4/vZY+yP3U5d5GABUVabR9WXV9t21TlqZeEPqFqas48R9jU0aoy6YcOekfH3o/OEbESqjDJPJhd1nw+ow1DLx+ZCTnnm1pvIZFlf5NbvjfoZ/6lla2pKpRr8pzanNiDOjcRltl96v/S1GgJtKYQqgXVtoRbyNKrBJqm6Qx8hmHHimR/HxxBsPW5jYen5Tb9Fpb1uf75+hFUZvQjSCf59P/OT7lPi/ukose/XjbZ7987a3us5BrcqnsTub2soWwoup5WYV8mIhUici8MAyyhZ7YIUCZ+HpP7038VNzx/sKcVs145uPySPoyfTllPMrhpPjhU0/0I/t1C4dYHCExKA658T1GBxQfOxEvNeqngbMDtgOAHha9Pff1eSxqE7Im16tX19SW0+/ueL+MNT4F/9FJD95ZUtXdB5wPfsdosWUUzdKqOuZVBO+aGxPCTMWM46iNMZNEZGDglgDX9X4pjNMoCeSrj1EEVPciBGHofkWGQsqfBYSzz8iRN4/K/8R5kGu2V/ocUvTM+yYBpIyo5xc1DcGHW/bNRy0il4tIqYiUVlcHEyxmD4lv9KswmLMmtS+vcwhfMnKtUYdFLsHbM+qbDyL6s6c/c86Vf1JZ8YFPTe3zH/qI9g7/u83TFVAd7lC8lRvDmb0aBmMXZg6Mli++zUw0xgwFhgIMHjw4kGf37t5PBJFswfDdRz5Oue/oW0anrFmMKwv+QcuHv76ZffdIpoki01ZsytWcUEmWC7+EYV5FrVOAZ6nU7R2GxyamC5iUPMFJi6uZW7HFyo5f27FqCrkSPvmWqH94Jf/OzCBojXjMfX1TG35U22103Y9dmJtP9ifDpnHiwN19tqY4sGp4nlK8TF6SekLEp8vjUftN5C9vziUOQ0t6ZFmWzFlTk3QSUiIWRTUoGLwMz3sR+AQ4XETWiMgvgjdLCYubcnArBMG9Yxbn/NvPyoMR8vYOw8g5uYUt8KtGH3SsDxHJavLKd/49hTvfLwvQIiUZXkZ9XBKGIYrihS2NrWzaun0v+w8e+ySQc/2/56d7mh6femRG/lXLoAfV/OCxT1iYZWwOJXzUR63EihP/MTanyTm5EGQME6/4FawoFdmIdLIYHslIZ3NbBMM5vZDO9WYD6qMuIqIY8+w3YYm00p1JPqzROHOVndPBf/yfzLFIokSFuojIJzi+kj2F1qkW13L+0wKIfqhCrSTle48UVjxfJX/iOs3/4gijH/qFCrWSlBkRNFGjXFU7H5aFtEZk1BRj0CVbUKFWrGGiDz5Qmygwz4figaBWdFehVhRF8YkJi4IJx6BCrSgBURXw0DrFPq5+aVYg6apQK4qiWI4KtaIoiuWoUCuKoliOCrWiKIrlqFAriqJYjgq1oiiK5ahQK4qiWI4KtaIoiuWoUCuKoliOCrWiKIrleBJqETlbRBaJyFIRuT5ooxRFUZTP8bK4bU/gYeAcYBBwiYgMCtowRVEUxcHLmoknAUuNMcsBROQl4AJggd/GHN30JM/teC97X/wgc8e9hKleQp/Tr2L3iX/htZb/Zq/d+3F6xzQqDv8p+/fZysdlq+jYuJyjvnoRex58HI99MJu/XXYuUvYu5bMn8dqK3nzQ50yeOLWe/yp7mKF7/plTy25ncMdsbtnxBjb1H8S9Vb9iS/sOlMgWKvc8mb03TuX1A27gotV3sKTPIJp67MgxTdP5rOO/OLHHYhbuexEdbc2YPv3Y58hT2GP89UhbI5+0D6LnwFM4afUwynY5mes2nsfOO/fjhbbfAzDkoGFsXPIZV5TMYWDbMkaeMJSxH35Ah/Tioh2mckbH5wu0fnjQNaza1MTP6h5j7t7fpe9O/bi9+Qc8VfHtbcdUn/Mk33uzjtVmL/501uF848gvsGvf3jw6YRmrNzcAMGFRNXdfdCz3jVlMXVMr8/52FtX1zbw2fQ13j1rEfrvtyAXH7ctJB+/BH1+dw4Bd+lBWWbftHNedfQQHD9iJh8cvY27FFk47bADH7NefRyYsY//dd2TM779K757C9JWbaWxtZ+Lias4/dh8mLqpm5Nx1lPTbgb+eN4jzH5rM8788maP368/Nb83jrVlr+dHJB3LaoQPYu39f/vzaHJZU1bNv/758c9BejF1YxZVnHMod7y3k8L37cf/Fx7NgbS0vf7aasQuddQx/ddrBPPHRCq4/5wjOOmpv9tttR6rrmynZZQdue3c+C9bW0tDSzgMXH887s9fy1JQVbG1pB+DO7x3D9SPm8r0T9uO+Hx7H+LIqdurTk/V1zXyybCO/O+NQ1tY0UlHTyMRF1YyYWcFN5w+id0/h7KP35qx/TaKxtZ2m1s+XBTvv2H3Yt39fpq3YxCUnHcjhe/fj0C/swoxVNayorkdEuOXt+Vx84gF0GMOR++zKiBkVtHcYnv75iXy6fBPjFq6nT68enHXU3hy1b38uevRj2jo6WF/rBHd67TdfobaplQ11LYjATn16ccoX96CuqY2ePYRpKzZx7auzAfj16V/k/GP3Zd7aLQzYZQdOO2wA936wiMraZr5+eAlDJy3nN189hOc+Xck9P/gSyzfU8/ynqzhin34MPmgP/vz6nG5rH07449e4YcRcTj1sAAD/HL0IgJcuP4XF6+vYt/+O/HJ4KQAH7LEjh5TsQu+ePdi3f1+e+WQlXz+8hP479ubSrwykrLKWR8YvY8iFR1NWWUdVXRMXHrcfPXsIw6asYMSMCv501uH8c/QiLjnpAC44bj8G7rkzre0dNLe1s3pTI49MWMpn5Zu56oxDuejL+zN7zRbmrqnh5IP35MnJy/n16Yew/+478uynK7nx3CO58OEpfOWQPWlobufSrxzER0s2cNEJ+3Hn+2Xbjjtq3/78+JSDeHfOWt51V6B/7hcn88wn5fzo5AM57Au70KeXU7+dX1HL81NXcu4x+9CrZw9ueWseu+3UJ2f9S4dkWrVBRL4PnG2M+aX7/VLgZGPMlV2Ouxy4HODAAw/88sqVK7M25pqXZvLVw0v47vH7Z/1ba+loB9MBPXtHbYk1LK2q45CSXZBCW6sqINraO+jZQ4rqem1pbKX/jsX1zojIdGPM4GT7fFuF3BgzFBgKMHjw4JzW7Ln/4uP9MsceevQEekZthVUc+oV+UZsQK3r1LL4+/2IT6Ux4eQIqgAMSvu/vblMURVFCwItQfwYcJiIHi0gf4GLg7WDNUhRFUTrJ6PowxrSJyJXAaJw2/DBjzPzALVMURVEAjz5qY8x7wHsB26IoiqIkofh6KRRFUWKGCrWiKIrlqFAriqJYjgq1oiiK5WScmZhToiLVQPZTEx0GABt8NMdmiiWvxZJP0LwWKmHk9SBjTEmyHYEIdT6ISGmqaZSFRrHktVjyCZrXQiXqvKrrQ1EUxXJUqBVFUSzHRqEeGrUBIVIseS2WfILmtVCJNK/W+agVRVGU7bGxRq0oiqIkoEKtKIpiOdYIdaEsoCsi5SIyV0RmiUipu20PERkjIkvc/3d3t4uIPOjmeY6InJCQzmXu8UtE5LKo8pOIiAwTkSoRmZewzbe8iciX3Wu31P1tJEuapMjnrSJS4d7XWSJybsK+G1ybF4nIWQnbkz7Tbsjgqe72l93wwZEgIgeIyHgRWSAi80Xkand7Id7XVHm1/94aYyL/wwmfugz4ItAHmA0MitquHPNSDgzosu1u4Hr38/XAXe7nc4H3AQFOAaa62/cAlrv/7+5+3t2CvJ0OnADMCyJvwDT3WHF/e45F+bwV+GOSYwe5z+sOwMHuc9y5rE/SZxp4BbjY/fwY8NsI7+k+wAnu537AYjdPhXhfU+XV+ntrS4162wK6xpgWoHMB3ULhAuAZ9/MzwIUJ24cbh0+B3URkH+AsYIwxZpMxZjMwBjg7bKO7YoyZBGzqstmXvLn7djXGfGqcp3x4QlqhkiKfqbgAeMkY02yMWQEsxXmekz7Tbm3yDOA19/eJ1yx0jDHrjDEz3M91wEJgPwrzvqbKayqsube2CPV+wOqE72tIfwFtxgAfiMh0cRb8BdjLGLPO/VwJ7OV+TpXvOF0Pv/K2n/u563abuNJt7g/rdAWQfT73BGqMMW1dtkeOiAwEjgemUuD3tUtewfJ7a4tQFxKnGmNOAM4BrhCR0xN3urWKghwTWch5Ax4FDgGOA9YB90Zrjr+IyC7A68A1xpjaxH2Fdl+T5NX6e2uLUBfMArrGmAr3/yrgDZxm0nq3CYj7f5V7eKp8x+l6+JW3Cvdz1+1WYIxZb4xpN8Z0AE/g3FfIPp8bcdwFvbpsjwwR6Y0jXM8bY0a4mwvyvibLaxzurS1CXRAL6IrIziLSr/Mz8C1gHk5eOnvBLwPecj+/DfzE7Uk/BdjiNjdHA98Skd3dZti33G024kve3H21InKK6+v7SUJakdMpWi7fxbmv4OTzYhHZQUQOBg7D6TxL+ky7tdPxwPfd3ydes9Bxr/V/gIXGmPsSdhXcfU2V11jc26B7Wr3+4fQmL8bpTf1L1PbkmIcv4vQAzwbmd+YDx3f1IbAEGAvs4W4X4GE3z3OBwQlp/Ryn82Ip8LOo8+ba9CJO07AVx//2Cz/zBgzGeUmWAf/GnTlrST6fdfMxB+cF3ifh+L+4Ni8iYURDqmfafU6mufl/Fdghwnt6Ko5bYw4wy/07t0Dva6q8Wn9vdQq5oiiK5dji+lAURVFSoEKtKIpiOSrUiqIolqNCrSiKYjkq1IqiKJajQq0oimI5KtSKoiiW8/8By7414Mpstv8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVad6ti-o2Hj",
        "colab_type": "text"
      },
      "source": [
        "## **Part B - The CVAE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OZz8uBVBrhnl",
        "colab_type": "text"
      },
      "source": [
        "# Step 2.1. Load and preprocess the dataset for the CVAE"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ImddJHztD07",
        "colab_type": "text"
      },
      "source": [
        "Define the \"one_hot vector\" that will append the Task_ID"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8yEkp7F2tK4B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_all_one_hot(tasks):\n",
        "  if os.path.isfile(join(PROJECT_PATH, 'meta_dataloader/all_one_hot.npy')):\n",
        "    all_one_hot = np.load(join(PROJECT_PATH, 'meta_dataloader/all_one_hot.npy'))\n",
        "  \n",
        "  else:\n",
        "\n",
        "  all_one_hot = []\n",
        "  new_one_hot = []\n",
        "  \n",
        "  cpt = 0\n",
        "      \n",
        "  for taskid in tasks.task_ids:\n",
        "        \n",
        "    one_hot = np.zeros((1,174))\n",
        "    one_hot[0, cpt] = 1\n",
        "    cpt += 1\n",
        "    print(cpt, one_hot)\n",
        "\n",
        "    #to use only when there is a need to limit the number of tasks\n",
        "    #if cpt > 5:\n",
        "      #break\n",
        "        \n",
        "    task = TCGA.TCGATask(taskid)\n",
        "    new_one_hot.append(one_hot)\n",
        "    \n",
        "    for j in range(0, len(task._samples)):\n",
        "      all_one_hot.append(new_one_hot[cpt-1])\n",
        "    \n",
        "\n",
        "  #all_one_hot = np.concatenate(all_one_hot, axis=0)\n",
        "  np.save(join(PROJECT_PATH, 'meta_dataloader/all_one_hot.npy'), all_one_hot)\n",
        "\n",
        "  return all_one_hot "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-Exb3lytCb4",
        "colab_type": "code",
        "outputId": "5874f9ff-6a50-4928-fb1d-10955e2e33ce",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "all_one_hot = load_all_one_hot(tasks)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "2 [[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "3 [[0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "4 [[0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "5 [[0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "6 [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "7 [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "8 [[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "9 [[0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "10 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "11 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "12 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "13 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "14 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "15 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "16 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "17 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "18 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "19 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "20 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "21 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "22 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "23 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "24 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "25 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "26 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "27 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "28 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "29 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "30 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "31 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "32 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "33 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "34 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "35 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "36 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "37 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "38 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "39 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "40 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "41 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "42 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "43 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "44 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "45 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "46 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "47 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "48 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "49 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "50 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "51 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "52 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "53 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "54 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "55 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "56 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "57 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "58 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "59 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "60 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "61 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "62 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "63 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "64 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "65 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "66 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "67 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "68 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "69 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "70 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "71 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "72 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "73 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "74 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "75 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "76 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "77 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "78 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "79 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "80 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "81 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "82 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "83 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "84 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "85 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "86 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "87 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "88 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "89 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "90 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "91 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "92 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "93 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "94 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "95 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "96 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "97 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "98 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "99 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "100 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "101 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "102 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "103 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "104 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "105 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "106 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "107 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "108 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "109 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "110 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "111 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "112 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "113 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "114 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "115 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "116 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "117 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "118 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "119 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "120 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "121 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "122 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "123 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "124 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "125 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "126 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "127 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "128 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "129 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "130 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "131 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "132 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "133 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "134 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "135 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "136 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "137 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "138 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "139 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "140 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "141 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "142 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "143 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "144 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "145 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "146 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "147 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "148 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "149 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "150 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "151 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "152 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "153 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "154 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "155 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "156 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "157 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "158 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "159 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "160 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "161 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "162 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "163 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "164 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "165 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "166 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "167 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "168 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            "  0. 0. 0. 0. 0. 0.]]\n",
            "169 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  1. 0. 0. 0. 0. 0.]]\n",
            "170 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 1. 0. 0. 0. 0.]]\n",
            "171 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 1. 0. 0. 0.]]\n",
            "172 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 1. 0. 0.]]\n",
            "173 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 1. 0.]]\n",
            "174 [[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
            "  0. 0. 0. 0. 0. 1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8OZPUNNptnlk",
        "colab_type": "text"
      },
      "source": [
        "Load_all_tasks_conditions_sets and define the new output (All_X_one_hot)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zFFxGmpyo1cK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_all_tasks_conditions_sets(tasks):\n",
        "  # When task ID is provided, each sample should be a vector [gene1, gene2, ...., gene20k, 0, 0, 0, 0, 1, 0, 0]\n",
        "  # How to compute one hot encoding of the ith task [0, 0, 0, 0, 1, 0, 0]?? vector zero everywhere but in the ith index\n",
        "  # one_hot = np.zeros(174)\n",
        "  # one_hot[cpt] = 1\n",
        "\n",
        "    # Here we load the arrays if they have been saved already\n",
        "    #if os.path.isfile(join(PROJECT_PATH, 'meta_dataloader/all_X.npy')):\n",
        "    all_X = np.load(join(PROJECT_PATH, 'meta_dataloader/all_X.npy'))\n",
        "    all_Y = np.load(join(PROJECT_PATH, 'meta_dataloader/all_Y.npy'))\n",
        "    all_one_hot = np.load(join(PROJECT_PATH, 'meta_dataloader/all_one_hot.npy'))\n",
        "    #else:\n",
        "\n",
        "      #all_X = []\n",
        "      #all_Y = []\n",
        "      #X_one_hot = []\n",
        "      #all_X_one_hot = []\n",
        "\n",
        "      #cpt = 0\n",
        "\n",
        "      #for taskid in tasks.task_ids:\n",
        "        \n",
        "        #one_hot = np.zeros((1,174))\n",
        "        #one_hot[0, cpt] = 1\n",
        "        #cpt += 1\n",
        "        #print(cpt, one_hot)\n",
        "\n",
        "        #to use only when there is a need to limit the number of tasks\n",
        "        #if cpt > 5:\n",
        "          #break\n",
        "        \n",
        "        #task = TCGA.TCGATask(taskid)\n",
        "        #all_X.append(task._samples)\n",
        "        #all_Y.append(task._labels)\n",
        "\n",
        "      #all_X = np.concatenate(all_X, axis=0)\n",
        "      #all_Y = np.concatenate(all_Y, axis=0)\n",
        "\n",
        "      #np.save(join(PROJECT_PATH, 'meta_dataloader/all_X.npy'), all_X)\n",
        "      #np.save(join(PROJECT_PATH, 'meta_dataloader/all_Y.npy'), all_Y)\n",
        "      \n",
        "      #all_one_hot = np.load(join(PROJECT_PATH, 'meta_dataloader/all_one_hot.npy'))\n",
        "\n",
        "      for i in range(0, len(all_X)):\n",
        "          X_one_hot = np.append(all_X[i], all_one_hot[i], axis=0)\n",
        "          all_X_one_hot.append(X_one_hot)\n",
        "\n",
        "          np.save(join(PROJECT_PATH, 'meta_dataloader/all_X_one_hot.npy'), all_X_one_hot)\n",
        "\n",
        "        \n",
        "  X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(all_X_one_hot,\n",
        "                                                                              all_Y, \n",
        "                                                                              train_size=0.8,\n",
        "                                                                              test_size=0.2)\n",
        "  all_train_conditions_set = TensorDataset( Tensor(X_train), Tensor(y_train))\n",
        "  all_test_conditions_set = TensorDataset( Tensor(X_test), Tensor(y_test))\n",
        "    \n",
        "  return all_train_conditions_set, all_test_conditions_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N5or6-c5U3g3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_all_tasks_conditions_sets(tasks):\n",
        "  all_X = np.load(join(PROJECT_PATH, 'meta_dataloader/all_X.npy'))\n",
        "  all_Y = np.load(join(PROJECT_PATH, 'meta_dataloader/all_Y.npy'))\n",
        "  all_one_hot = np.load(join(PROJECT_PATH, 'meta_dataloader/all_one_hot.npy'))\n",
        "\n",
        "  all_X_one_hot = []\n",
        "  X_one_hot = []\n",
        "\n",
        "  for i in range(0, len(all_X)):\n",
        "    X_one_hot = np.append(all_X[i], all_one_hot[i], axis=0)\n",
        "    all_X_one_hot.append(X_one_hot)\n",
        "    all_X_one_hot = np.concatenate(all_X_one_hot, axis=0)\n",
        "\n",
        "  np.save(join(PROJECT_PATH, 'meta_dataloader/all_X_one_hot.npy'), all_X_one_hot)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(all_X_one_hot,\n",
        "                                                                              all_Y, \n",
        "                                                                              train_size=0.8,\n",
        "                                                                              test_size=0.2)\n",
        "  all_train_conditions_set = TensorDataset( Tensor(X_train), Tensor(y_train))\n",
        "  all_test_conditions_set = TensorDataset( Tensor(X_test), Tensor(y_test))\n",
        "  return all_train_conditions_set, all_test_conditions_set"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVKsWmC_o8nB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_train_conditions_set, all_test_conditions_set = load_all_tasks_conditions_sets(tasks)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LoPvJiQ0jF8J",
        "colab_type": "code",
        "outputId": "8db028a7-c81d-44dc-fde1-f233debf14fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        }
      },
      "source": [
        "# You should have train_set instead of X_train as input\n",
        "# 32 is the max batch size to use \n",
        "train_CVAE_loader = torch.utils.data.DataLoader(all_train_conditions_set, batch_size=32, shuffle=True)\n",
        "test_CVAE_loader = torch.utils.data.DataLoader(all_test_conditions_set, batch_size=32, shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-68b4f85745a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_CVAE_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_train_conditions_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_CVAE_loader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_test_conditions_set\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'all_train_conditions_set' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3SreespGJaho",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(train_CVAE_loader.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEe6H52SjW9j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_CVAE_loader))\n",
        "print(len(test_CVAE_loader))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gpmz_p1SulrF",
        "colab_type": "text"
      },
      "source": [
        "# Step 2.2. : Define the CVAE model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cwBnV1AdTTix",
        "colab_type": "text"
      },
      "source": [
        "Updated Auto-encoder code provided by Paul\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eDyuDCi2azJ6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.nn.utils import spectral_norm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "class Dummy(torch.nn.Module):\n",
        "    \"\"\"\n",
        "    Helper class that allows you to do nothing. Replaces `lambda x: x`.\n",
        "    \"\"\"\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x\n",
        "\n",
        "\n",
        "class LinearBatch(nn.Module):\n",
        "    \"\"\"A linear layer with batch normalization.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, bias=True):\n",
        "        super(LinearBatch, self).__init__()\n",
        "        self.linear = nn.Linear(input_dim, output_dim, bias=bias)\n",
        "        self.batch_norm = nn.BatchNorm1d(output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.linear(x)\n",
        "        return self.batch_norm(out)\n",
        "\n",
        "\n",
        "class LinearSpec(nn.Module):\n",
        "    \"\"\"A linear layer with spectral normalization.\"\"\"\n",
        "    def __init__(self, input_dim, output_dim, bias=True):\n",
        "        super(LinearSpec, self).__init__()\n",
        "        self.linear = spectral_norm(nn.Linear(input_dim, output_dim, bias=bias))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.linear(x)\n",
        "\n",
        "\n",
        "class LinearLayers(nn.Module):\n",
        "    \"\"\"\n",
        "    A basic feed forward network with configurable dropout and layer-wise\n",
        "    normalization.\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, dropout=0, norm='none', modulelist=False,\n",
        "                 bias=True, activate_final=True):\n",
        "        super(LinearLayers, self).__init__()\n",
        "\n",
        "        norm_dict = {\n",
        "            'batch': LinearBatch, 'spectral': LinearSpec, 'none': nn.Linear}\n",
        "\n",
        "        assert 0 <= dropout < 1\n",
        "        assert norm in norm_dict.keys()\n",
        "\n",
        "        # Set up the linear layers.\n",
        "        self.linear = norm_dict[norm]\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.activation = nn.ReLU()\n",
        "\n",
        "        arch = []\n",
        "        n_layers = len(layers)\n",
        "        for i in range(n_layers-1):\n",
        "            arch.append(self.linear(layers[i], layers[i+1], bias=bias))\n",
        "\n",
        "            # Add activation to all layers, except the final one optionally.\n",
        "            if activate_final or i+1 < n_layers-1:\n",
        "                arch.append(self.activation)\n",
        "\n",
        "                # Only dropout the activated layers.\n",
        "                if dropout > 0:\n",
        "                    arch.append(self.dropout)\n",
        "\n",
        "        # Allows for the linear layer to be a passthrough in the case that\n",
        "        # the number of layers requested is empty or a single value.\n",
        "        if len(arch) > 0:\n",
        "            if modulelist:\n",
        "                self.model = nn.ModuleList(arch)\n",
        "            else:\n",
        "                self.model = nn.Sequential(*arch)\n",
        "        else:\n",
        "            self.model = Dummy()\n",
        "\n",
        "    def embed(self, X):\n",
        "        return self.model(X)\n",
        "\n",
        "    def forward(self, X):\n",
        "        return self.embed(X)\n",
        "\n",
        "\n",
        "class AutoEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A basic feed forward classifier architecture with configurable dropout and\n",
        "    layer-wise normalization.\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, dropout=0, norm='none'):\n",
        "        \"\"\"\n",
        "        An MLP vanilla antoencoder.\n",
        "        \"\"\"\n",
        "        super(AutoEncoder, self).__init__()\n",
        "\n",
        "        # assert num_classes >= 1\n",
        "        self.encoder = LinearLayers(layers=layers, dropout=dropout, norm=norm)\n",
        "        self.decoder = LinearLayers(layers=layers[::-1], dropout=dropout,\n",
        "                                    norm=norm, activate_final=False)\n",
        "        self.criterion = torch.nn.MSELoss(reduction='sum')\n",
        "\n",
        "    def embed(self, x):\n",
        "        return self.encoder(x)\n",
        "\n",
        "    def forward(self, x, fingerprint=0, compound=0, line=0):\n",
        "        z = self.encoder(x)\n",
        "        X_prime = self.decoder(z)\n",
        "        return {'z': z, 'x_prime': X_prime, 'x': x}\n",
        "\n",
        "    def loss(self, outputs):\n",
        "        recon_loss = self.criterion(outputs['x_prime'], outputs['x'])\n",
        "        return {'recon_loss': recon_loss}\n",
        "\n",
        "\n",
        "class VariationalAutoEncoder(nn.Module):\n",
        "    \"\"\"\n",
        "    A basic feed forward classifier architecture with configurable dropout and\n",
        "    layer-wise normalization with ~*~ variational inference ~*~.\n",
        "    \"\"\"\n",
        "    def __init__(self, layers, beta=1, dropout=0, norm='none'):\n",
        "        \"\"\"\n",
        "        An MLP variational antoencoder.\n",
        "        \"\"\"\n",
        "        super(VariationalAutoEncoder, self).__init__()\n",
        "\n",
        "        self.encoder = LinearLayers(layers=layers[:-1], dropout=dropout, norm=norm)\n",
        "        self.mu = LinearLayers(layers=[layers[-2], layers[-1]], activate_final=False)\n",
        "        self.logvar = LinearLayers(layers=[layers[-2], layers[-1]], activate_final=False)\n",
        "        self.decoder = LinearLayers(layers=layers[::-1], dropout=dropout,\n",
        "                                    norm=norm, activate_final=False)\n",
        "        self.criterion = torch.nn.MSELoss(reduction='sum')\n",
        "        self.beta = beta\n",
        "\n",
        "    def embed(self, X):\n",
        "        h = self.encoder(X)\n",
        "        mu = self.mu(h)\n",
        "        logvar = self.logvar(h)\n",
        "\n",
        "        return mu, logvar\n",
        "\n",
        "    def reparameterize(self, mu, logvar):\n",
        "        std = torch.exp(0.5 * logvar)\n",
        "        eps = torch.rand_like(std)\n",
        "        z = mu + (std * eps)\n",
        "\n",
        "        return z\n",
        "\n",
        "    def decode(self, z):\n",
        "        x_prime = self.decoder(z)\n",
        "        return x_prime\n",
        "\n",
        "    def forward(self, x, fingerprint=0, compound=0, line=0):\n",
        "        mu, logvar = self.embed(x)\n",
        "        z = self.reparameterize(mu, logvar)\n",
        "        x_prime = self.decoder(z)\n",
        "        return {'z': z, 'x_prime': x_prime, 'x': x, 'mu': mu, 'logvar': logvar}\n",
        "\n",
        "    def loss(self, outputs):\n",
        "        recon_loss = self.criterion(outputs['x_prime'], outputs['x'])\n",
        "        kl_div = -0.5 * torch.sum(1 + outputs['logvar'] - outputs['mu'].pow(2) - outputs['logvar'].exp())\n",
        "\n",
        "        # Apply beta scaling factor\n",
        "        kl_div *= self.beta\n",
        "\n",
        "        return {'recon_loss': recon_loss, 'kl_div': kl_div}\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yfoM7N22aYD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_CVAE = VariationalAutoEncoder(layers=[20530, 100, 50], dropout=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H48ezfqC2mTq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_CVAE"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4YuXP_Mu1g3",
        "colab_type": "text"
      },
      "source": [
        "# Step 2.3. Optimizer step (learning rate)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llWN_v08TBfO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "The loss was already defined in the VAE, we are only adding the Adam optimizer\n",
        "\"\"\"\n",
        "import torch.optim as optim\n",
        "\n",
        "# Define the optimizer, learning rate \n",
        "optimizer = optim.Adam(model_CVAE.parameters(), lr=0.0001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tIyR1TGpwSq",
        "colab_type": "text"
      },
      "source": [
        "# Step 2.4. - Calculate the CVAE training loss and the valid loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qeOobdYmTBkg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_training_losses = []\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs): \n",
        "      for i, (inputs, labels) in enumerate(train_CVAE_loader, 0):\n",
        "\n",
        "#pdb.set_trace()\n",
        "        # forward propogation\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # calculate the loss\n",
        "        losses = model.loss(outputs)\n",
        "        loss = losses['recon_loss'] + losses['kl_div']\n",
        "# pdb.set_trace()\n",
        "\n",
        "        #\"ajouter la loss a la fin de liste de toutes les loss (all_losses) avec .append /.detach() « detache » ton tensor torch du graph de computation / .numpy() convertit le tensor en numpy array\"\n",
        "        all_training_losses.append(loss.detach().numpy())\n",
        "\n",
        "        # backpropogation + update parameters\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        cost = loss.item()\n",
        "        if i % 100 == 0:    # print every 1000 iterations\n",
        "            print('Epoch:' + str(epoch) + \", Iteration: \" + str(i) \n",
        "                  + \", CVAE training cost = \" + str(cost))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3KUwyz2p9AD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " # Compute validation error (we don't use the backpropagation and the update of the parametres in the validation error step)\n",
        " all_valid_loss= []\n",
        " num_epochs = 20\n",
        "\n",
        " for epoch in range(num_epochs): \n",
        "      for i, (inputs, labels) in enumerate(test_CVAE_loader, 0):\n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        # calculate the loss\n",
        "        valid_losses = model.loss(outputs)\n",
        "        valid_loss = valid_losses['recon_loss'] + valid_losses['kl_div']\n",
        "        #pdb.set_trace()\n",
        "\n",
        "        #Save all the training losses in a list.append /.detach() « detache » ton tensor torch du graph de computation / .numpy() convertit le tensor en numpy array\"\n",
        "        all_valid_loss.append(valid_loss.detach().numpy())\n",
        "\n",
        "        # print statistics\n",
        "        cost = valid_loss.item()\n",
        "        if i % 100 == 0:    # print every 1000 iterations\n",
        "            print('Epoch:' + str(epoch) + \", Iteration: \" + str(i) \n",
        "                  + \", CVAE valid cost = \" + str(cost))\n",
        "            \n",
        "    #print(np.mean(all_valid_loss)) \"doesn't seem to work\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ulMTqU_bIq3N",
        "colab_type": "text"
      },
      "source": [
        "# 2.5. Visualize the CVAE loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuS6roIFQPHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(all_training_losses)\n",
        "plt.title(\"CVAE Training loss\")\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoTfakYPx1CS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(all_valid_loss)\n",
        "plt.title(\"CVAE Valid loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oimi-3raCNiq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.plot(all_training_losses)\n",
        "plt.plot(all_valid_loss)\n",
        "plt.title(\"CVAE Training loss VS Valid loss\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qm2_QBd_aHlY",
        "colab_type": "text"
      },
      "source": [
        "## TODO\n",
        "\n",
        "- Compute the valid loss and plot the valid loss in another plot (separated from the training loss) - Done but only for the 4 first tasks\n",
        "\n",
        "- Clean the code #Rihab- Done\n",
        "\n",
        "- Modify the load_all_tasks_sets function in order to return the ID of the task for each sample -- Not done yet\n",
        "\n",
        "- Figure out what is the difference between conditional VAE and VAE, and send your answer to Paul for validation\n",
        "\n",
        "\n",
        "    #Rihab response:\n",
        "    **Difference Autoencoder VS Variational Autoencoder**: VAE works by making the latent space more predictable, more continuous, less sparse. By forcing latent variables to become normally distributed, VAEs gain control over the latent space.\n",
        "    **Difference VAE VS CVAE**: CVAE allows modeling the input based on both the latent variables (like the VAE), but also to based on an additional information such the Task_ID or Task_name in the TCGA_Benchmark case.\n",
        "    Ref: https://towardsdatascience.com/variational-autoencoders-vaes-for-dummies-step-by-step-tutorial-69e6d1c9d8e9\n",
        "\n",
        "- modify (DO NOT TAKE ANYTHING FROM OUTSIDE) the VAE code in order to have a conditional VAE code. (it should be around 2 lines of code to add)\n",
        "\n",
        "    #Rihab - Code lines to use\n",
        "\n",
        "    In the encoder: \n",
        "    X = Input(batch_shape=())\n",
        "    cond = Input(batch_shape=())\n",
        "    inputs = merge([X, cond], mode='concat', concat_axis=1)\n",
        "    \n",
        "    In the decoder: \n",
        "    z_cond = merge([z, cond], mode='concat', concat_axis=1)\n",
        "\n",
        "- Tweak learning rate (lr parameter in the optimizer), number of epochs, architecture of the VAE etc in order to have a \"good\" final valid loss. (do not spend too much time on this)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8AgvM3w7pfi",
        "colab_type": "text"
      },
      "source": [
        "## Step 6 -  Definition of the evaluation metrics\n",
        "\n",
        "We will use accuracy as an evaluation metric"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkZDV37a76St",
        "colab_type": "text"
      },
      "source": [
        "## Step 7 - Report results on the train and test data (using the evaluation metric)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6PuZY0pQfNY4",
        "colab_type": "text"
      },
      "source": [
        "Various Models\n",
        "*   CNN: spatial data & many filters\n",
        "*   GAN: generator & discriminator\n",
        "*   AE: Encoder & Decoder, features learned through compressions\n",
        "*   VAE: trade-off of latent loss & reconstruction loss; hidden neurons fit into a specific distribution\n",
        "*   cVAE: latent variables, data, both conditioned to some random variables\n",
        "\n",
        "*   VAE vs AE: VAE added the distribution fitting & latent vector\n",
        "*   VAE vs cVAE: cVAE added the conditions using one-hot vectors"
      ]
    }
  ]
}